{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3184ecb4-0b5e-44bf-b87d-0f58c53a65ae",
   "metadata": {
    "id": "4757c902-32c1-45a1-99e9-b42d5b22c903",
    "tags": []
   },
   "source": [
    "# Operationalizing machine learning models\n",
    "\n",
    "### Welcome!\n",
    "In this tutorial you will trian a machine learning model to be used in production... \n",
    "\n",
    "We'll use a widely known dataset with creditcard transactions which are classified as legitimate or fraudulent. Most of the features are components generated by a [Principle Component Analysis](https://en.wikipedia.org/wiki/Principal_component_analysis), which is done to remove any personally identifiable information. \n",
    "\n",
    "During these assignments we will use the widely popular python libaries [Pandas (v1.3.5)](https://pandas.pydata.org/pandas-docs/version/1.3/index.html), [sklearn (v1.0.2)](https://scikit-learn.org/1.0/user_guide.html) and [matplotlib (v.3.2.2)](https://matplotlib.org/3.2.2/tutorials/index.html)\n",
    "\n",
    "You will be programming in pairs, so try to form pairs where at least one of you is comfortable with Python and preferrably also with the used libraries. If not, it's no problem; we're here to help throughout the assignments.\n",
    "\n",
    "[<img src=\"https://www.monkeyuser.com/assets/images/2020/178-pair-programming.png\" alt=\"drawing\" width=\"400\"/>](https://www.monkeyuser.com/2020/pair-programming/)\n",
    "\n",
    "### To start, run the next cell to download the data and other source code used during the assignments: highlight the cell and press Shift + Enter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ac96609-56c5-4e93-9afb-2f003e532052",
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/SIDN/tma22_ml.git"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24a96894-f725-4ee9-a07f-665f7cbb941c",
   "metadata": {
    "id": "406903e2-6cd4-45ee-b874-d580f5344761",
    "tags": []
   },
   "source": [
    "## Part 1: Training an initial model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4900c9f2-9611-43f7-96ea-3d42057e2b8a",
   "metadata": {
    "id": "703173b4-9c35-451a-9016-7466c510842d"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import clone\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn.metrics import *\n",
    "from sklearn.model_selection import train_test_split, cross_validate\n",
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68ec2693-7235-486c-9447-9bf6fc904bff",
   "metadata": {
    "id": "f483d140-9433-4fcf-97b9-25a686753104",
    "tags": []
   },
   "source": [
    "### Data exploration\n",
    "\n",
    "#### Let's load all the available data and freely explore it, just to see what we're dealing with.\n",
    "For now, we'll discard the target class (fraudent or legitimate transaction), because in real life we don't have this much ground truth data in the exploration phase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "384a4c57-8544-4240-b8d7-27206951dbda",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 394
    },
    "id": "2adcbb92-08a1-48ea-84b8-27010b1a1795",
    "outputId": "08824fd0-9f62-49ec-90a5-b1b72a961ab5"
   },
   "outputs": [],
   "source": [
    "url_creditcard_holdout = 'tma22_ml/data/creditcard_holdout.csv.gz'\n",
    "url_creditcard_week1_2 = 'tma22_ml/data/creditcard_1-2.csv.gz'\n",
    "url_creditcard_week3_52 = 'tma22_ml/data/creditcard_3-52.csv.gz'\n",
    "\n",
    "all_data = pd.concat([pd.read_csv(url_creditcard_week1_2, compression='gzip'), \n",
    "                      pd.read_csv(url_creditcard_week3_52, compression='gzip')]).drop('target', axis=1)\n",
    "all_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29c3037e-4c8b-418b-977b-0b29d1fb8218",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 483
    },
    "id": "8145c474-7a50-4a94-8de2-c3e5561e1a6c",
    "outputId": "4c39cd92-c104-444c-f269-3776c7bd240c"
   },
   "outputs": [],
   "source": [
    "# Let's visualize the distribution of a sample of some of the variables\n",
    "columns = [f'v{x}' for x in range(1, 11)]\n",
    "plt.figure(figsize=(24, 8));\n",
    "plt.grid(axis='y');\n",
    "all_data.sample(frac=0.05)[columns].boxplot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1416cf7-d83f-458a-ad75-4d13a9c2afb3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 390
    },
    "id": "e9bc987f-8583-49bd-98c5-d6568cce165f",
    "outputId": "36b1c95c-a3e3-4754-bdf9-30d8c19614b2"
   },
   "outputs": [],
   "source": [
    "# Now we plot the amount spent in a transaction; we see the \n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 6))\n",
    "ax1.set_title('Transaction amount')\n",
    "ax2.set_title('Transaction amount (log transformed)')\n",
    "\n",
    "ax1.boxplot(all_data.amount)\n",
    "ax2.boxplot(np.log(all_data.amount + 1))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4514f2d-0569-43c4-a3a7-09b9bcb3b501",
   "metadata": {
    "id": "2d38f7bc-096a-4f94-91de-2ef19a866aff"
   },
   "source": [
    "#### It is clear the scale of the amount variable is not well suited for the models that we're dealing with. Most of the transactions are under $100, with outliers reaching thousands of dollars. The large values can skew the model disproportionally to the other variables.\n",
    "#### Let's scale the data to a smaller range with a log transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44a6705a-6d29-489d-9420-e1cd8ce291a5",
   "metadata": {
    "id": "63289880-04b5-45f0-b448-4444d847cb20"
   },
   "outputs": [],
   "source": [
    "all_data['log_amount'] = np.log(all_data.amount + 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2722fcc4-3968-4d22-b492-2832cb5ec1ff",
   "metadata": {
    "id": "b8788ba6-0b01-4a9f-a305-1e11ed61329e",
    "tags": []
   },
   "source": [
    "#### Now explore the data further in the next cell! Create some graphs to visualize the data and get to know it better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6789c6d3-e5f3-469b-99f8-2153a9e11b8b",
   "metadata": {
    "id": "9c34274e-b000-4fd8-a777-42b2023bda4e"
   },
   "outputs": [],
   "source": [
    "###\n",
    "...\n",
    "\n",
    "###"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c62d82b-23d8-47a8-b790-28ef07798d0b",
   "metadata": {
    "id": "bfe99c00-6a73-46b1-b056-1a32d17d921a",
    "tags": []
   },
   "source": [
    "### Our initial dataset\n",
    "\n",
    "#### We select the first two weeks of data as our initial training set.\n",
    "This represents a short period in which an equal number of suspicious and legitimate domain names were thoroughly examined by our Support staff to determine their label. \\\n",
    "Don't forget to log-transform the amount column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25b246b0-f2cf-426c-ba3c-b4e9ef5a1e12",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 655
    },
    "id": "b5bb331b-aa50-4f7a-91f7-3a34ffb3fa34",
    "outputId": "ccc044aa-39b5-455f-8e42-04a6498b7477"
   },
   "outputs": [],
   "source": [
    "# Load all data from week 1 and 2\n",
    "data_weeks_1_2 = pd.read_csv(url_creditcard_week1_2, compression='gzip')\n",
    "# Transform amount to the log of amount\n",
    "data_weeks_1_2['amount'] = np.log(data_weeks_1_2.amount + 1)\n",
    "\n",
    "# We simulate the scenario where we only have the ground thruth labels for 30 fraudulent and 30 legitimate transactions; this is what our support staff has labeled.\n",
    "initial_dataset = (data_weeks_1_2\n",
    "                  .sample(frac=1, random_state=42)  # Shuffle the data to get random data points\n",
    "                  .groupby('target')  # group the data in two groups: fraudulent and malicious\n",
    "                  .head(30))  # Take the first 30 data points from each group\n",
    "\n",
    "initial_dataset.target.value_counts().plot(kind='bar', title='Ground truth labels')\n",
    "initial_dataset.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8885304-d652-4325-9c3a-7cd65612dfdc",
   "metadata": {
    "id": "2eeb46f6-1863-4a89-b758-29aeadac3a15",
    "tags": []
   },
   "source": [
    "### Classifier & scoring\n",
    "#### Now we have 72 data points with their ground truth labels; we can train our initial model!\n",
    "\n",
    "**Assignment:** define two classifiers (you can use those implemented in the sklearn module) and evaluate their performance using cross-validation on our limited dataset. Try at least one interpretable model. Feel free to experiment with the model parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f831551-d4ee-4a82-84ed-2a246c6819a5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 112
    },
    "id": "cec2257d-b373-401c-8e99-736814b0a080",
    "outputId": "175102ca-ba82-4c6b-bb7f-59df9d5daf2d"
   },
   "outputs": [],
   "source": [
    "# Let's define some metrics by which we can measure the performance of our model\n",
    "scoring = {\n",
    "    'ap': make_scorer(average_precision_score),  # Average precision (weighted mean of precisions achieved at each threshold)\n",
    "    'precision': make_scorer(precision_score),  # Precision (true positives / all positive classifications)\n",
    "    'recall': make_scorer(recall_score),  # Recall (fraction of fraudulent samples the classifier found)\n",
    "    'specificity': make_scorer(recall_score, pos_label=0),  # Speicificity (fraction of legitimate samples classified as legitimate)\n",
    "}\n",
    "\n",
    "############# YOUR CODE HERE\n",
    "# Some examples: https://scikit-learn.org/stable/auto_examples/classification/plot_classifier_comparison.html\n",
    "\n",
    "clf = RandomForestClassifier()\n",
    "\n",
    "clf2 = ...\n",
    "\n",
    "#############\n",
    "\n",
    "classifier = clf\n",
    "\n",
    "# Using cross-validation, we evaluate the model using the four scoring metrics defined above.\n",
    "scores = pd.DataFrame(cross_validate(classifier, initial_dataset.loc[:, initial_dataset.columns != 'target'], initial_dataset.target, cv=5, scoring=scoring))\n",
    "scores.agg(['mean', 'std'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e400d25-5a0e-4b14-b24f-5514732e038c",
   "metadata": {
    "id": "272e4ddb-4a6d-4e2b-ac95-2225e0e07cf9"
   },
   "source": [
    "### Testing on the holdout set\n",
    "\n",
    "#### Of course, in practice we do not have the luxury of this rather large holdout set to test our performance on. Often, we have to make do with heuristics and weakly labaled data.\n",
    "#### Today, we'll use this holdout set to accurately monitor the performance of the model on unseen data, as we later start to improve the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68ce8003-c464-48b3-a0e4-4bfa8e873a93",
   "metadata": {
    "id": "e5326c97-0f91-44b8-ac6c-e8e170a00d2e"
   },
   "outputs": [],
   "source": [
    "holdout_dataset = pd.read_csv(url_creditcard_holdout, compression='gzip')  # Load data from csv\n",
    "holdout_dataset['amount'] = np.log(holdout_dataset.amount + 1)  # Log-transform the amount column"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "789dc4dc-3974-46e6-b8e9-d0c90862425a",
   "metadata": {},
   "source": [
    "#### Now we do have the target class for this large dataset. First visualize the target class distribution to get an idea about the skew we are dealing with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "446ca628-1505-4a2e-8376-171e422b4c2f",
   "metadata": {
    "id": "gsfT_yT5X-Qz"
   },
   "outputs": [],
   "source": [
    "### Your code here\n",
    "\n",
    "###"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccc602c5-3652-483a-969a-40fc94ae1689",
   "metadata": {},
   "source": [
    "#### Given this distribution, which method for evaluating our model is best suited? \n",
    "In the cell below we compute the model's probability of fraud for each transaction. Use these metrics to evaluate the model's performance. \n",
    "Check out the [sklearn.metrics documentation](https://scikit-learn.org/stable/modules/classes.html#classification-metrics) for a list of evaluation metrics. Also scroll down to the [plotting](https://scikit-learn.org/stable/modules/classes.html#id4) section for some useful plot generators. ([example](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.PrecisionRecallDisplay.html#sklearn.metrics.PrecisionRecallDisplay.from_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d6cc8ed-2ea9-4c0f-b133-e28b658425d0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 279
    },
    "id": "883301fe-8b41-48f5-be6b-84e080e16042",
    "outputId": "080830be-d442-4231-945c-3fea327f7177"
   },
   "outputs": [],
   "source": [
    "# First we fit our classifier to the initial dataset for which we have the ground truth data\n",
    "X = initial_dataset.loc[:, initial_dataset.columns != 'target']  # All columns except the target\n",
    "y = initial_dataset.target  # target class\n",
    "classifier.fit(X, y)\n",
    "\n",
    "# Now let's test the performance on the holdout set. Here we plot the precision-recall curve, showing the trade-off between a high precision and a high recall\n",
    "y_proba = classifier.predict_proba(holdout_dataset.loc[:, holdout_dataset.columns != 'target'])[:, 1]  # The model's probability scores of a transaction being fraudulent\n",
    "\n",
    "\n",
    "### Your code here\n",
    "\n",
    "# PrecisionRecallDisplay.from_predictions(holdout_dataset.target, y_proba);\n",
    "\n",
    "###"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "183ddd4e-afee-4495-9887-8ab31c320ef2",
   "metadata": {
    "id": "57a702e4-1823-4a26-b0c2-edc44a013663"
   },
   "source": [
    "#### Our average precision is not bad, but it can be a lot better!\n",
    "\n",
    "### Tuning the model\n",
    "We need to choose a threshold above which our model should classify a transaction as fraudulent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "949da0a9-a08c-491c-bf97-5f3da35e388d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 404
    },
    "id": "ddc27482-a4bf-4dd9-a593-db0b648dc755",
    "outputId": "b9c1e3c4-5e94-4fdd-92f7-0462bb31e4bb"
   },
   "outputs": [],
   "source": [
    "precision, recall, thresholds = precision_recall_curve(holdout_dataset.target, y_proba)\n",
    "thresholds = np.append(thresholds, np.nan)\n",
    "\n",
    "fig = plt.figure(figsize=(10, 6))\n",
    "plt.title('Precision vs Recall at various thresholds')\n",
    "plt.xlabel('Decision threshold')\n",
    "plt.plot(thresholds, precision, label='Precision');\n",
    "plt.plot(thresholds, recall, label='Recall');\n",
    "plt.grid();\n",
    "plt.legend();\n",
    "plt.plot();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2836a17d-4522-4442-b0ab-b28902a77195",
   "metadata": {
    "id": "50bc4db6-5c82-451d-9273-ebd2ca997275"
   },
   "source": [
    "### How to decide on a threshold?\n",
    "First we will see what happens when we set the threshold at some arbitrary values. Play around with different threshold to see how the outcome changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af25ec27-699f-4b5c-a987-768f1dbe39fd",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 279
    },
    "id": "12da4bbb-5430-4c61-8513-d18555980d01",
    "outputId": "9c6b8df1-d882-4b29-b4fc-af1dd0295ba3"
   },
   "outputs": [],
   "source": [
    "threshold = ...\n",
    "assert threshold >= 0 and threshold <= 1, \"Threshold must be between 0 and 1.\"\n",
    "y_pred = y_proba > threshold\n",
    "\n",
    "ConfusionMatrixDisplay.from_predictions(holdout_dataset.target, y_pred, display_labels=['Benign', 'Fraud']);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c1e979a-7a40-43fa-920c-6f47c665826f",
   "metadata": {
    "id": "7619eb38-cbbb-49dc-ab50-79901943d6c4"
   },
   "source": [
    "#### Think about what these values mean for a production environment. \n",
    "\n",
    "Take the suspicious registration checker we presented as an example. Evaluating a suspicious domain name can take up to 15 minutes. some simple calculations reveal that, with 2500 new registrations per day, a precision of 99% means 25 false positives, taking around 6 hours to evaluate! That's 0.8 FTE wasted on checking false-positive results.\n",
    "\n",
    "This shows that the evaluation of a model should be done taking into account the production environment it is deployed in. Writing a paper in which we advance the state-of-the-art for exampel by obtaining 97% precision sounds good on paper, but is still not usable in real life. \n",
    "\n",
    "TODO\\\n",
    "expliciet maken dat ze zelf een theshold moeten kiezen voor een regcheck usecase. In Menti aangeven wat ze kiezen (model + threshold)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TMA",
   "language": "python",
   "name": "tma"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
