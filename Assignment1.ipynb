{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3184ecb4-0b5e-44bf-b87d-0f58c53a65ae",
   "metadata": {
    "id": "3184ecb4-0b5e-44bf-b87d-0f58c53a65ae",
    "tags": []
   },
   "source": [
    "# Part 1: train initial TransacCheck models\n",
    "\n",
    "## Welcome\n",
    "\n",
    "In this tutorial you will train a machine learning model to be used in production... \n",
    "\n",
    "We'll use a well-known dataset with creditcard transactions which are classified as legitimate or fraudulent. Most of the features are components generated by a [Principle Component Analysis](https://en.wikipedia.org/wiki/Principal_component_analysis), which is done to remove any personally identifiable information. \n",
    "\n",
    "During these assignments we will use the widely popular python libraries [Pandas (v1.3.5)](https://pandas.pydata.org/pandas-docs/version/1.3/index.html), [sklearn (v1.0.2)](https://scikit-learn.org/1.0/user_guide.html) and [matplotlib (v.3.2.2)](https://matplotlib.org/3.2.2/tutorials/index.html)\n",
    "\n",
    "You will be programming in pairs, so try to form pairs where at least one of you is comfortable with Python and preferably also with the used libraries. If not, it's no problem; we're here to help throughout the assignments.\n",
    "\n",
    "[<img src=\"https://www.monkeyuser.com/assets/images/2020/178-pair-programming.png\" alt=\"drawing\" width=\"400\"/>](https://www.monkeyuser.com/2020/pair-programming/)\n",
    "\n",
    "## Download data\n",
    "\n",
    "To start, run the next cell to download the data and other source code used during the assignments: highlight the cell and press Shift + Enter.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ac96609-56c5-4e93-9afb-2f003e532052",
   "metadata": {
    "id": "7ac96609-56c5-4e93-9afb-2f003e532052"
   },
   "outputs": [],
   "source": [
    "!git clone https://github.com/SIDN/tma22_ml.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4900c9f2-9611-43f7-96ea-3d42057e2b8a",
   "metadata": {
    "id": "4900c9f2-9611-43f7-96ea-3d42057e2b8a"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import clone\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn.metrics import *\n",
    "from sklearn.model_selection import train_test_split, cross_validate\n",
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68ec2693-7235-486c-9447-9bf6fc904bff",
   "metadata": {
    "id": "68ec2693-7235-486c-9447-9bf6fc904bff",
    "tags": []
   },
   "source": [
    "## Data exploration\n",
    "\n",
    "### Read data\n",
    "\n",
    "Let's load all the available data and freely explore it, just to see what we're dealing with. For now, we'll discard the target class (fraudulent or legitimate transaction), because in real life we don't have this much ground truth data in the exploration phase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "384a4c57-8544-4240-b8d7-27206951dbda",
   "metadata": {
    "id": "384a4c57-8544-4240-b8d7-27206951dbda"
   },
   "outputs": [],
   "source": [
    "url_creditcard_holdout = 'tma22_ml/data/creditcard_holdout.csv.gz'\n",
    "url_creditcard_week1_2 = 'tma22_ml/data/creditcard_1-2.csv.gz'\n",
    "url_creditcard_week3_52 = 'tma22_ml/data/creditcard_3-52.csv.gz'\n",
    "\n",
    "all_data = pd.concat([pd.read_csv(url_creditcard_week1_2, compression='gzip'), \n",
    "                      pd.read_csv(url_creditcard_week3_52, compression='gzip')]).drop('target', axis=1)\n",
    "all_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ufUxow1NNjk",
   "metadata": {
    "id": "8ufUxow1NNjk"
   },
   "source": [
    "## Explore data\n",
    "\n",
    "We visualize the distribution of the raw transaction amount and the log transformed amount using [boxplots](https://en.wikipedia.org/wiki/Box_plot)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1416cf7-d83f-458a-ad75-4d13a9c2afb3",
   "metadata": {
    "id": "c1416cf7-d83f-458a-ad75-4d13a9c2afb3"
   },
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 6))\n",
    "ax1.set_title('Transaction amount')\n",
    "ax2.set_title('Transaction amount (log transformed)')\n",
    "\n",
    "ax1.boxplot(all_data.amount)\n",
    "ax2.boxplot(np.log(all_data.amount + 1))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4514f2d-0569-43c4-a3a7-09b9bcb3b501",
   "metadata": {
    "id": "a4514f2d-0569-43c4-a3a7-09b9bcb3b501"
   },
   "source": [
    "It is clear the scale of the amount variable is not well suited for the models that we're dealing with. Most of the transactions are under $100, with outliers reaching thousands of dollars. The large values can skew the model disproportionally to the other variables.\n",
    "\n",
    "Let's scale the data to a smaller range with a log transform:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44a6705a-6d29-489d-9420-e1cd8ce291a5",
   "metadata": {
    "id": "44a6705a-6d29-489d-9420-e1cd8ce291a5"
   },
   "outputs": [],
   "source": [
    "all_data['log_amount'] = np.log(all_data.amount + 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2722fcc4-3968-4d22-b492-2832cb5ec1ff",
   "metadata": {
    "id": "2722fcc4-3968-4d22-b492-2832cb5ec1ff",
    "tags": []
   },
   "source": [
    "**Assignment:** Explore the data further in the next cell! Create some graphs to visualize the data and get to know it better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6789c6d3-e5f3-469b-99f8-2153a9e11b8b",
   "metadata": {
    "id": "6789c6d3-e5f3-469b-99f8-2153a9e11b8b"
   },
   "outputs": [],
   "source": [
    "### Your code here\n",
    "...\n",
    "\n",
    "###"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c62d82b-23d8-47a8-b790-28ef07798d0b",
   "metadata": {
    "id": "0c62d82b-23d8-47a8-b790-28ef07798d0b",
    "tags": []
   },
   "source": [
    "## Initial dataset\n",
    "\n",
    "We select the first two weeks of data as our initial training set.\n",
    "This represents a short period in which an equal number of suspicious and legitimate domain names were thoroughly examined by our Support staff to determine their label. \\\n",
    "Don't forget to log-transform the amount column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25b246b0-f2cf-426c-ba3c-b4e9ef5a1e12",
   "metadata": {
    "id": "25b246b0-f2cf-426c-ba3c-b4e9ef5a1e12"
   },
   "outputs": [],
   "source": [
    "# Load all data from week 1 and 2\n",
    "data_weeks_1_2 = pd.read_csv(url_creditcard_week1_2, compression='gzip')\n",
    "# Transform amount to the log of amount\n",
    "data_weeks_1_2['amount'] = np.log(data_weeks_1_2.amount + 1)\n",
    "\n",
    "# We simulate the scenario where we only have the ground thruth labels for 30 fraudulent and 30 legitimate transactions; this is what our support staff has labeled.\n",
    "initial_dataset = (data_weeks_1_2\n",
    "                  .sample(frac=1, random_state=42)  # Shuffle the data to get random data points\n",
    "                  .groupby('target')  # group the data in two groups: fraudulent and malicious\n",
    "                  .head(30))  # Take the first 30 data points from each group\n",
    "\n",
    "initial_dataset.target.value_counts().plot(kind='bar', title='Ground truth labels')\n",
    "initial_dataset.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "q25o_sdEQ7k7",
   "metadata": {
    "id": "q25o_sdEQ7k7"
   },
   "outputs": [],
   "source": [
    "initial_dataset.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8885304-d652-4325-9c3a-7cd65612dfdc",
   "metadata": {
    "id": "c8885304-d652-4325-9c3a-7cd65612dfdc",
    "tags": []
   },
   "source": [
    "## Classifier & scoring\n",
    "\n",
    "Now we have 60 data points with their ground truth labels; we can train our initial model!\n",
    "\n",
    "**Assignment:** define at least two classifiers (you can use those implemented in the [sklearn module](https://scikit-learn.org/stable/supervised_learning.html) and evaluate their performance using [k-fold cross-validation](https://scikit-learn.org/stable/modules/cross_validation.html#k-fold) on our limited dataset. Try at least one interpretable model. Feel free to experiment with the model parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f831551-d4ee-4a82-84ed-2a246c6819a5",
   "metadata": {
    "id": "8f831551-d4ee-4a82-84ed-2a246c6819a5"
   },
   "outputs": [],
   "source": [
    "# Let's define some metrics by which we can measure the performance of our model\n",
    "scoring = {\n",
    "    'ap': make_scorer(average_precision_score),  # Average precision (weighted mean of precisions achieved at each threshold)\n",
    "    'precision': make_scorer(precision_score),  # Precision (true positives / all positive classifications)\n",
    "    'recall': make_scorer(recall_score),  # Recall (fraction of fraudulent samples the classifier found)\n",
    "    'specificity': make_scorer(recall_score, pos_label=0),  # Speicificity (fraction of legitimate samples classified as legitimate)\n",
    "}\n",
    "\n",
    "### Your code here\n",
    "# Some examples: https://scikit-learn.org/stable/auto_examples/classification/plot_classifier_comparison.html\n",
    "\n",
    "clf = RandomForestClassifier()\n",
    "\n",
    "clf2 = ...\n",
    "\n",
    "###\n",
    "\n",
    "classifier = clf\n",
    "\n",
    "# Using cross-validation, we evaluate the model using the four scoring metrics defined above.\n",
    "# Documentation on cross-validation https://scikit-learn.org/stable/modules/cross_validation.html\n",
    "scores = pd.DataFrame(cross_validate(classifier, initial_dataset.loc[:, initial_dataset.columns != 'target'], initial_dataset.target, cv=5, scoring=scoring))\n",
    "scores.agg(['mean', 'std'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e400d25-5a0e-4b14-b24f-5514732e038c",
   "metadata": {
    "id": "9e400d25-5a0e-4b14-b24f-5514732e038c"
   },
   "source": [
    "### Testing on the holdout set\n",
    "\n",
    "If we look at the table above, the model seems to perform well. Both the scores are high and the standard deviation between folds is low indicating that the performance is stable.\n",
    "\n",
    "Let's verify these results with a representative hold-out set. Keep in mind that in practice we do not have the luxury of this rather large holdout set to test our performance on. Often, we have to make do with heuristics and weakly labaled data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68ce8003-c464-48b3-a0e4-4bfa8e873a93",
   "metadata": {
    "id": "68ce8003-c464-48b3-a0e4-4bfa8e873a93"
   },
   "outputs": [],
   "source": [
    "holdout_dataset = pd.read_csv(url_creditcard_holdout, compression='gzip')  # Load data from csv\n",
    "holdout_dataset['amount'] = np.log(holdout_dataset.amount + 1)  # Log-transform the amount column"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "789dc4dc-3974-46e6-b8e9-d0c90862425a",
   "metadata": {
    "id": "789dc4dc-3974-46e6-b8e9-d0c90862425a"
   },
   "source": [
    "**Assignment:** Visualize the target class distribution to get an idea about the skew we are dealing with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "446ca628-1505-4a2e-8376-171e422b4c2f",
   "metadata": {
    "id": "446ca628-1505-4a2e-8376-171e422b4c2f"
   },
   "outputs": [],
   "source": [
    "### Your code here\n",
    "\n",
    "###"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccc602c5-3652-483a-969a-40fc94ae1689",
   "metadata": {
    "id": "ccc602c5-3652-483a-969a-40fc94ae1689"
   },
   "source": [
    "**Assignment:** Given this distribution, which evaluation curve our model is best suited (ROC, Precicion-Recall, DET, etc.)? \n",
    "\n",
    "In the cell below we compute the model's probability of fraud for each transaction in the hold-out set. Use these metrics to evaluate the model's performance. \n",
    "Check out the [`sklearn.metrics` documentation](https://scikit-learn.org/stable/modules/classes.html#classification-metrics) for a list of evaluation metrics. Also scroll down to the [plotting](https://scikit-learn.org/stable/modules/classes.html#id4) section for some useful plot generators. ([example](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.PrecisionRecallDisplay.html#sklearn.metrics.PrecisionRecallDisplay.from_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d6cc8ed-2ea9-4c0f-b133-e28b658425d0",
   "metadata": {
    "id": "6d6cc8ed-2ea9-4c0f-b133-e28b658425d0"
   },
   "outputs": [],
   "source": [
    "# First we fit our classifier to the initial dataset for which we have the ground truth data\n",
    "X = initial_dataset.loc[:, initial_dataset.columns != 'target']  # All columns except the target\n",
    "y = initial_dataset.target  # target class\n",
    "classifier.fit(X, y)\n",
    "\n",
    "# Now let's test the performance on the holdout set. Here we plot the precision-recall curve, showing the trade-off between a high precision and a high recall\n",
    "y_proba = classifier.predict_proba(holdout_dataset.loc[:, holdout_dataset.columns != 'target'])[:, 1]  # The model's probability scores of a transaction being fraudulent\n",
    "\n",
    "\n",
    "### Your code here, plot the evaluation curve of your choice\n",
    "\n",
    "###"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "183ddd4e-afee-4495-9887-8ab31c320ef2",
   "metadata": {
    "id": "183ddd4e-afee-4495-9887-8ab31c320ef2"
   },
   "source": [
    "### Tuning the model\n",
    "\n",
    "As we have seen, most classifiers return probabilities between 0 and 1.\n",
    "We thus need to choose a threshold above which our model should classify a transaction as fraudulent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "949da0a9-a08c-491c-bf97-5f3da35e388d",
   "metadata": {
    "id": "949da0a9-a08c-491c-bf97-5f3da35e388d"
   },
   "outputs": [],
   "source": [
    "precision, recall, thresholds = precision_recall_curve(holdout_dataset.target, y_proba)\n",
    "thresholds = np.append(thresholds, np.nan)\n",
    "\n",
    "fig = plt.figure(figsize=(10, 6))\n",
    "plt.title('Precision vs Recall at various thresholds')\n",
    "plt.xlabel('Decision threshold')\n",
    "plt.plot(thresholds, precision, label='Precision');\n",
    "plt.plot(thresholds, recall, label='Recall');\n",
    "plt.grid();\n",
    "plt.legend();\n",
    "plt.plot();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2836a17d-4522-4442-b0ab-b28902a77195",
   "metadata": {
    "id": "2836a17d-4522-4442-b0ab-b28902a77195"
   },
   "source": [
    "**Assignment:** Play around with different threshold in the cell below to see how the outcome changes with respect to true positives, false positives, true negatives and false negative.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af25ec27-699f-4b5c-a987-768f1dbe39fd",
   "metadata": {
    "id": "af25ec27-699f-4b5c-a987-768f1dbe39fd"
   },
   "outputs": [],
   "source": [
    "threshold = ...\n",
    "assert type(threshold) == float, \"Threshold should be a float.\"\n",
    "assert threshold >= 0 and threshold <= 1, \"Threshold must be between 0 and 1.\"\n",
    "y_pred = y_proba > threshold\n",
    "\n",
    "ConfusionMatrixDisplay.from_predictions(holdout_dataset.target, y_pred, display_labels=['Benign', 'Fraud']);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c1e979a-7a40-43fa-920c-6f47c665826f",
   "metadata": {
    "id": "1c1e979a-7a40-43fa-920c-6f47c665826f"
   },
   "source": [
    "**Assignment:** Think about what these values mean for a production environment. \n",
    "\n",
    "Take the suspicious registration checker we presented as an example. Evaluating a suspicious domain name can take up to 15 minutes. Some simple calculations reveal that, with 2500 new registrations per day, a precision of 99% means 25 false positives, taking around 6 hours to evaluate! That's 0.8 FTE wasted on checking false-positive results.\n",
    "\n",
    "This shows that the evaluation of a model should be done taking into account the production environment it is deployed in. Writing a paper in which we advance the state-of-the-art for example by obtaining 97% precision sounds good on paper, but is still not usable in real life. \n",
    "\n",
    "**Assignment:** Submit the classifier and threshold you selected through Menti (code 3393 6819).\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "-ztFdruCWaaS",
   "metadata": {
    "id": "-ztFdruCWaaS"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Assignment1.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "TMA",
   "language": "python",
   "name": "tma"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
