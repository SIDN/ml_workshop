{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "609ec38d-0d9d-49ff-a585-e54625ff2f81",
   "metadata": {
    "id": "609ec38d-0d9d-49ff-a585-e54625ff2f81"
   },
   "source": [
    "# Part 2: Improving the model with Active Learning\n",
    "\n",
    "We are simulating an operational environment where every week analysts are able to label 50 data points to use as additional training data; they simply don't have the time to label more. \n",
    "\n",
    "The challenge is to select those data points where you expect the models to improve the most. Unfortunately, you can only calculate afterwards whether the models actually improved with the additional training data.\n",
    "\n",
    "[<img src=\"https://miro.medium.com/max/1400/0*1K-VniGulGWWsQA9\" alt=\"meme\" width=\"500\"/>](https://towardsdatascience.com/use-active-learning-to-boost-your-ml-problem-53c70f72b979)\n",
    "\n",
    "## Download data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7a1ef1f-0ea9-43b0-b3ee-b8cb658d7a74",
   "metadata": {
    "id": "d7a1ef1f-0ea9-43b0-b3ee-b8cb658d7a74"
   },
   "outputs": [],
   "source": [
    "!git clone https://github.com/SIDN/ml_workshop.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5552d1a-7ea0-49dc-8566-cc9592489f6a",
   "metadata": {
    "id": "f5552d1a-7ea0-49dc-8566-cc9592489f6a"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from typing import List\n",
    "from sklearn import clone\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn.metrics import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "xnZy_4V0Yc3R",
   "metadata": {
    "id": "xnZy_4V0Yc3R"
   },
   "source": [
    "## Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c69fc778-af6b-4c56-9158-76ccc34f2654",
   "metadata": {
    "id": "c69fc778-af6b-4c56-9158-76ccc34f2654"
   },
   "outputs": [],
   "source": [
    "path_to_creditcard_holdout = 'ml_workshop/data/creditcard_holdout.csv.gz'\n",
    "path_to_creditcard_week1_2 = 'ml_workshop/data/creditcard_1-2.csv.gz'\n",
    "path_to_creditcard_week3_52 = 'ml_workshop/data/creditcard_3-52.csv.gz'\n",
    "\n",
    "# All data from weeks 1 and 2\n",
    "data_weeks_1_2 = pd.read_csv(path_to_creditcard_week1_2, compression='gzip')\n",
    "data_weeks_1_2['amount'] = np.log(data_weeks_1_2.amount + 1)\n",
    "\n",
    "# Our training data currently conisists of the 60 initially labeled data points\n",
    "training_data = (data_weeks_1_2\n",
    "                  .sample(frac=1, random_state=42)  # Shuffle the data to get random data points\n",
    "                  .groupby('target')  # group the data in two groups: fraudulent and malicious\n",
    "                  .head(30))  # Take the first 30 data points from each group\n",
    "\n",
    "# Load the holdout dataset\n",
    "holdout_dataset = pd.read_csv(path_to_creditcard_holdout, compression='gzip')\n",
    "holdout_dataset['amount'] = np.log(holdout_dataset.amount + 1)\n",
    "\n",
    "# All data from weeks 3 through 52 -- including labels. We'll simulate going through this dataset week by week\n",
    "data_weeks_3_52 = pd.read_csv(path_to_creditcard_week3_52, compression='gzip')\n",
    "data_weeks_3_52['amount'] = np.log(data_weeks_3_52.amount + 1)\n",
    "\n",
    "# Our omniscient oracle which we can query for the labels once we have made our sample selection\n",
    "oracle = data_weeks_3_52.target\n",
    "\n",
    "# The now unlabeled data for weeks 3 - 52.\n",
    "data_weeks_3_52.drop('target', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "foNVs5BkbeFc",
   "metadata": {
    "id": "foNVs5BkbeFc"
   },
   "source": [
    "## Define initial classifier\n",
    "\n",
    "The default is to use a Random Forest classifier. You can also change this to a different method or to the best classifier obtained in part 1.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "id8AB-t-bKrN",
   "metadata": {
    "id": "id8AB-t-bKrN"
   },
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ba43355-1a32-42f2-b239-6ef20094e130",
   "metadata": {
    "id": "5ba43355-1a32-42f2-b239-6ef20094e130"
   },
   "source": [
    "## Introduce sampling strategies\n",
    "\n",
    "Now it is time move to the active learning part. To get you started we implemented 3 common sampling methods:\n",
    "\n",
    "- `UniformSampling`: Just select a number of random data points\n",
    "- `UncertaintySampling`: Select the samples closest to the decision boundary of the model\n",
    "- `CommitteeDisagreementSampling`: Select samples of which a \"committee\" of models have different opinions (some say it's legitimate, some say it's fraudulent)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b81b3e94-487b-4820-a7e0-7d7a96425056",
   "metadata": {
    "id": "b81b3e94-487b-4820-a7e0-7d7a96425056"
   },
   "outputs": [],
   "source": [
    "from ml_workshop.al.uniform_sampling import UniformSampling\n",
    "from ml_workshop.al.uncertainty_sampling import UncertaintySampling\n",
    "from ml_workshop.al.committee_sampling import CommitteeDisagreementSampling\n",
    "from ml_workshop.al import SamplingMethod"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "zk0KFrqnaBAH",
   "metadata": {
    "id": "zk0KFrqnaBAH"
   },
   "source": [
    "All strategies implement the `SamplingMethod` abstract class. Let's read the docs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "qWKLu9rnaC9S",
   "metadata": {
    "id": "qWKLu9rnaC9S"
   },
   "outputs": [],
   "source": [
    "?SamplingMethod"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51tYzSYFal32",
   "metadata": {
    "id": "51tYzSYFal32"
   },
   "source": [
    "All sampling methods implement the `select_batch` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ZRa7q7KYZz0M",
   "metadata": {
    "id": "ZRa7q7KYZz0M"
   },
   "outputs": [],
   "source": [
    "?CommitteeDisagreementSampling.select_batch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62yDQd2AZJyG",
   "metadata": {
    "id": "62yDQd2AZJyG"
   },
   "source": [
    "The strategies are defined in the `ml_workshop/al` directory. If you have some time left, try to come up with your own strategy!\n",
    "\n",
    "## Update model using sampling strategy\n",
    "\n",
    "### Preperation\n",
    "\n",
    "**Assignment:** Create a voting committee of models to be used in the `CommitteeDisagreementSampling` method. This should be a list of at least two sklearn classifiers, and can be any combination. Try out different models and different model parameters!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e54a99b-f850-466e-81d9-d14348162939",
   "metadata": {
    "id": "7e54a99b-f850-466e-81d9-d14348162939"
   },
   "outputs": [],
   "source": [
    "### Begin your code here\n",
    "\n",
    "committee: List[BaseEstimator] = ...\n",
    "\n",
    "### End your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "imA46Ysedhzn",
   "metadata": {
    "id": "imA46Ysedhzn"
   },
   "source": [
    "In the next cells you will go through each week, selecting 50 samples following a sampling strategy.\n",
    "This can be done using two different modes:\n",
    "\n",
    "- *Interactive mode*: you can re-run the **Magic cell** below multiple times and select a different sampling strategy for each week. \n",
    "- *Automatic mode*: simulate a number of weeks of active learning using the same sampling strategy for each weak.\n",
    "\n",
    "**Assignment:** Select interactive or automatic mode. We recommend starting with interactive, because then you have more control over the strategy used. If you want to try again using another strategy or mode, run all the cells from the top of this notebook. To be extra safe you can restart the runtime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b222b31a-55bd-451e-ab6c-743ad2741893",
   "metadata": {
    "id": "b222b31a-55bd-451e-ab6c-743ad2741893"
   },
   "outputs": [],
   "source": [
    "### Begin your code here\n",
    "\n",
    "INTERACTIVE_MODE = True  # You choose: Interactive or automatic\n",
    "\n",
    "### End your code here\n",
    "\n",
    "# With the following lists we keep track of the model's performance over the weeks\n",
    "ap_per_week = []\n",
    "precision_recall_per_week = []\n",
    "labels_per_week = []\n",
    "\n",
    "week_nr = 3  # Week from which to start simulating the active learning loop\n",
    "\n",
    "if not INTERACTIVE_MODE:  # Automatic mode\n",
    "    weeks_to_simulate = 30\n",
    "    assert weeks_to_simulate <= 50, \"We have one year of data and start at week 3\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6omBC5hIguwD",
   "metadata": {
    "id": "6omBC5hIguwD"
   },
   "source": [
    "### Magic cell ðŸª„\n",
    "\n",
    "The cell below runs the active learning magic. In interactive mode run the follow cell multiple times to simulate each iteration of active learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2d5fedf-e0d8-4a94-a870-cbe3fc499fa3",
   "metadata": {
    "id": "a2d5fedf-e0d8-4a94-a870-cbe3fc499fa3"
   },
   "outputs": [],
   "source": [
    "### Begin your code here\n",
    "\n",
    "strategy = ...  # Set the sampling strategy you want to use for the next iteration(s)\n",
    "\n",
    "### End your code here\n",
    "\n",
    "\n",
    "# for each week in automatic mode, or one week in interactive mode:\n",
    "for week_nr in [week_nr] if INTERACTIVE_MODE else tqdm(range(week_nr, week_nr + weeks_to_simulate)):\n",
    "    if week_nr > 52:\n",
    "        print('No more data to simulate active learning.')\n",
    "        break\n",
    "        \n",
    "    # The pool of unlabeled data consists of all data of this one week\n",
    "    unlabeled_pool = data_weeks_3_52[data_weeks_3_52.week_no == week_nr]\n",
    "    \n",
    "    # Fit the classifier to the currently available training data\n",
    "    clf.fit(training_data.loc[:, training_data.columns!='target'], training_data.target)\n",
    "    \n",
    "    # If the strategy is a Committee Disagreement Sampling strategy, we also need to fit the committee models\n",
    "    if strategy == CommitteeDisagreementSampling:\n",
    "        for model in committee:\n",
    "            model.fit(training_data.loc[:, training_data.columns!='target'], training_data.target)\n",
    "\n",
    "    # Select unlabeled data points for which we want analysts to provide the ground truth label\n",
    "    selected_indices = strategy.select_batch(unlabeled_pool, nr_samples=50, model=clf, committee=committee)\n",
    "    queried_data = unlabeled_pool.loc[selected_indices]\n",
    "    queried_data['target'] = oracle.loc[selected_indices]\n",
    "\n",
    "    # Add the now labeled data to our training dataset\n",
    "    training_data = pd.concat([training_data, queried_data])\n",
    "\n",
    "    # Evaluate the new model on the holdout set! (cheat mode)\n",
    "    clf.fit(training_data.loc[:, training_data.columns!='target'], training_data.target)\n",
    "    # The model's probability scores of a transaction being fraudulent\n",
    "    y_pred = clf.predict(holdout_dataset.loc[:, holdout_dataset.columns != 'target'])\n",
    "    y_proba = clf.predict_proba(holdout_dataset.loc[:, holdout_dataset.columns != 'target'])[:, 1]\n",
    "    \n",
    "    labels_per_week.append(training_data.target.value_counts().values.tolist())\n",
    "    ap_per_week.append(average_precision_score(holdout_dataset.target, y_proba))\n",
    "    precision_recall_per_week.append([precision_score(holdout_dataset.target, y_pred), recall_score(holdout_dataset.target, y_pred)])\n",
    "    \n",
    "    if INTERACTIVE_MODE:\n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 6))\n",
    "        fig.suptitle(f'week_nr {week_nr} \\n Re-run this cell for the next week', fontsize=16)\n",
    "        ax2.set_title('Precision - recall curve')\n",
    "        training_data.target.value_counts().plot(kind='bar', title='Training data labels', ax=ax1)\n",
    "        ax1.grid(axis='y')\n",
    "        PrecisionRecallDisplay.from_predictions(holdout_dataset.target, y_proba, ax=ax2);\n",
    "        week_nr += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d1adf23-d29b-41b7-9042-04ca60119c42",
   "metadata": {
    "id": "3d1adf23-d29b-41b7-9042-04ca60119c42"
   },
   "source": [
    "## Evaluate model improvement\n",
    "\n",
    " Now let's look at a summary of the active learning experiment. Did our model improve?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41de626a-e3ea-45ad-a322-1ff22b3b3ebe",
   "metadata": {
    "id": "41de626a-e3ea-45ad-a322-1ff22b3b3ebe"
   },
   "outputs": [],
   "source": [
    "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(18, 14))\n",
    "fig.suptitle('Active learning summary', fontsize=16)\n",
    "plt.setp([ax1, ax2, ax3], xlabel='AL iteration')\n",
    "\n",
    "# Samples per iteration\n",
    "ax1.plot(range(1, len(labels_per_week) + 1), labels_per_week); ax1.grid(axis='y'); ax1.legend(['Number legitimate', 'Number fraudulent']); ax1.set_title('Training samples per iteration');\n",
    "ax2.plot(range(1, len(ap_per_week) + 1), ap_per_week); ax2.grid(axis='y'); ax2.set_title('Average Precision per iteration');\n",
    "ax3.plot(range(1, len(precision_recall_per_week) + 1), precision_recall_per_week); ax3.grid(axis='y'); ax3.legend(['Precision', 'Recall']); ax3.set_title('Precision and recall per iteration');\n",
    "PrecisionRecallDisplay.from_predictions(holdout_dataset.target, y_proba, ax=ax4); ax4.set_title('Final precision / recall curve');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3814c55a-eaea-4c92-92c6-86eab7e7ee86",
   "metadata": {
    "id": "3814c55a-eaea-4c92-92c6-86eab7e7ee86",
    "tags": []
   },
   "source": [
    "## Next steps\n",
    "\n",
    "**Asignment** Now that you've tested a sampling strategy, it's time to compare different strategies. You can keep the following questions in mind: Which of the sampling strategies worked best overall? How do different classifiers perform before and after active learning? How might we further improve the model?\n",
    "\n",
    "**Assignment:** Submit your best performing strategy and the achieved Average Precision through Menti.com (code 3393 6819)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aC4sQihhsvC",
   "metadata": {
    "id": "8aC4sQihhsvC"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Assignment2.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
