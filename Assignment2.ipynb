{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "609ec38d-0d9d-49ff-a585-e54625ff2f81",
   "metadata": {
    "id": "9346c694-4c9b-4c6d-b619-5ebb583c61b8"
   },
   "source": [
    "## Part 2: Improving the model with Active Learning\n",
    "\n",
    "We are simulating an operational environment where every week analysts are able to label 50 data points to use as additional training data; they simply don't have the time to label more. \n",
    "\n",
    "The challenge is to select those data points where you expect the models to improve the most. Unfortunately, you can only calculate afterwards whether the models actually improved with the additional training data.\n",
    "\n",
    "[<img src=\"https://miro.medium.com/max/1400/0*1K-VniGulGWWsQA9\" alt=\"meme\" width=\"500\"/>](https://towardsdatascience.com/use-active-learning-to-boost-your-ml-problem-53c70f72b979)\n",
    "\n",
    "#### Let's start by importing the necessary libraries and loading all the available data..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7a1ef1f-0ea9-43b0-b3ee-b8cb658d7a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/SIDN/tma22_ml.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5552d1a-7ea0-49dc-8566-cc9592489f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from typing import List\n",
    "from sklearn import clone\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn.metrics import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c69fc778-af6b-4c56-9158-76ccc34f2654",
   "metadata": {
    "id": "9ae37e7a-ab42-47a6-bd5a-3e95cb71d32e"
   },
   "outputs": [],
   "source": [
    "path_to_creditcard_holdout = 'tma22_ml/data/creditcard_holdout.csv.gz'\n",
    "path_to_creditcard_week1_2 = 'tma22_ml/data/creditcard_1-2.csv.gz'\n",
    "path_to_creditcard_week3_52 = 'tma22_ml/data/creditcard_3-52.csv.gz'\n",
    "\n",
    "# All data from weeks 1 and 2\n",
    "data_weeks_1_2 = pd.read_csv(path_to_creditcard_week1_2, compression='gzip')\n",
    "data_weeks_1_2['amount'] = np.log(data_weeks_1_2.amount + 1)\n",
    "\n",
    "# Our training data currently conisists of the 60 initially labeled data points\n",
    "training_data = (data_weeks_1_2\n",
    "                  .sample(frac=1, random_state=42)  # Shuffle the data to get random data points\n",
    "                  .groupby('target')  # group the data in two groups: fraudulent and malicious\n",
    "                  .head(30))  # Take the first 30 data points from each group\n",
    "\n",
    "# Load the holdout dataset\n",
    "holdout_dataset = pd.read_csv(path_to_creditcard_holdout, compression='gzip')\n",
    "holdout_dataset['amount'] = np.log(holdout_dataset.amount + 1)\n",
    "\n",
    "# All data from weeks 3 through 52 -- including labels. We'll simulate going through this dataset week by week\n",
    "data_weeks_3_52 = pd.read_csv(path_to_creditcard_week3_52, compression='gzip')\n",
    "data_weeks_3_52['amount'] = np.log(data_weeks_3_52.amount + 1)\n",
    "\n",
    "# Our omniscient oracle which we can query for the labels once we have made our sample selection\n",
    "oracle = data_weeks_3_52.target\n",
    "\n",
    "# The now unlabeled data for weeks 3 - 52.\n",
    "data_weeks_3_52.drop('target', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ba43355-1a32-42f2-b239-6ef20094e130",
   "metadata": {
    "id": "e5cc133d-6b4e-4a96-9620-8b6fc8a8b678"
   },
   "source": [
    "Now it is time to go through each week, selecting 50 samples following a sampling strategy. To get you started we implemented 3 common sampling methods:\n",
    "\n",
    "- `UniformSampling`: Just select a number of random data points\n",
    "- `UncertaintySampling`: Select the samples closest to the decision boundary of the model\n",
    "- `CommitteeDisagreementSampling`: Select samples of which a \"committee\" of models have different opinions (some say it's legitimate, some say it's fraudulent)\n",
    "\n",
    "These strategies are defined in the `al` directory. If you have some time left, try to come up with your own strategy!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b81b3e94-487b-4820-a7e0-7d7a96425056",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tma22_ml.al.uniform_sampling import UniformSampling\n",
    "from tma22_ml.al.uncertainty_sampling import UncertaintySampling\n",
    "from tma22_ml.al.committee_sampling import CommitteeDisagreementSampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e54a99b-f850-466e-81d9-d14348162939",
   "metadata": {
    "id": "88cc0234-e577-4a7c-9f26-0e93190b176f"
   },
   "outputs": [],
   "source": [
    "# Create a voting committee of models to be used in the CommitteeDisagreementSampling strategy:\n",
    "# This should be a list of sklearn classifiers, and can be any combination.\n",
    "# Try out different models and different model parameters\n",
    "\n",
    "### Your code here\n",
    "\n",
    "committee: List[BaseEstimator] = ... # e.g. [RandomForestClassifier(random_state=i) for i in range(10)]\n",
    "\n",
    "###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b222b31a-55bd-451e-ab6c-743ad2741893",
   "metadata": {
    "id": "569a3c90-8097-41db-abcf-13995374ff2f"
   },
   "outputs": [],
   "source": [
    "# Here you can choose between two modes of exploring the Active Learning magic: \n",
    "# Interactive mode: where you can re-run the next cell multiple times to see the results of each week of added labeled data. This way you can choose a different sampling strategy for each week.\n",
    "# Automatic mode: simulate a number of weeks of active learning with a sampling strategy\n",
    "# If you want to try again using another strategy or mode, run all the cells from the top of this notebook. To be extra safe you can restart the runtime.\n",
    "\n",
    "### Your code here\n",
    "\n",
    "INTERACTIVE_MODE = False  # You choose: Interactive or automatic\n",
    "\n",
    "classifier = ...  # Your best classifier from part 1 - you might need to import the model from the sklearn library\n",
    "\n",
    "###\n",
    "\n",
    "classifier.fit(training_data.loc[:, training_data.columns!='target'], training_data.target)\n",
    "\n",
    "ap_per_week = []\n",
    "precision_recall_per_week = []\n",
    "labels_per_week = []\n",
    "\n",
    "week_nr = 3  # Week from which to start simulating the active learning loop (3 - 52)\n",
    "\n",
    "if not INTERACTIVE_MODE:  # Automatic mode\n",
    "    weeks_to_simulate = 30\n",
    "    assert weeks_to_simulate <= 50, \"We have one year of data and start at week 3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2d5fedf-e0d8-4a94-a870-cbe3fc499fa3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e169a84c-c05b-4b2b-ba06-772c0f4fc432",
    "outputId": "d22b0e91-85d8-4451-f29d-ddd132b139ad"
   },
   "outputs": [],
   "source": [
    "####### Choose your sample strategy:\n",
    "\n",
    "strategy = ...\n",
    "\n",
    "#######\n",
    "\n",
    "# for each week in automatic mode, or one week in interactive mode:\n",
    "for week_nr in [week_nr] if INTERACTIVE_MODE else tqdm(range(week_nr, week_nr + weeks_to_simulate)):\n",
    "    if week_nr > 52:\n",
    "        print('No more data to simulate active learning.')\n",
    "        break\n",
    "        \n",
    "    # The pool of unlabeled data consists of all data of this one week\n",
    "    unlabeled_pool = data_weeks_3_52[data_weeks_3_52.week_no == week_nr]\n",
    "    \n",
    "    # Fit the classifier to the currently available training data\n",
    "    classifier.fit(training_data.loc[:, training_data.columns!='target'], training_data.target)\n",
    "    \n",
    "    # If the strategy is a Committee Disagreement Sampling strategy, we also need to fit the committee models\n",
    "    if strategy == CommitteeDisagreementSampling:\n",
    "        for model in committee:\n",
    "            model.fit(training_data.loc[:, training_data.columns!='target'], training_data.target)\n",
    "\n",
    "    # Select unlabeled data points for which we want analysts to provide the ground truth label\n",
    "    selected_indices = strategy.select_batch(unlabeled_pool, nr_samples=50, model=classifier, committee=committee)\n",
    "    queried_data = unlabeled_pool.loc[selected_indices]\n",
    "    queried_data['target'] = oracle.loc[selected_indices]\n",
    "\n",
    "    # Add the now labeled data to our training dataset\n",
    "    training_data = pd.concat([training_data, queried_data])\n",
    "\n",
    "    # Evaluate the new model on the holdout set! (cheat mode)\n",
    "    classifier.fit(training_data.loc[:, training_data.columns!='target'], training_data.target)\n",
    "    # The model's probability scores of a transaction being fraudulent\n",
    "    y_pred = classifier.predict(holdout_dataset.loc[:, holdout_dataset.columns != 'target'])\n",
    "    y_proba = classifier.predict_proba(holdout_dataset.loc[:, holdout_dataset.columns != 'target'])[:, 1]\n",
    "    \n",
    "    labels_per_week.append(training_data.target.value_counts().values.tolist())\n",
    "    ap_per_week.append(average_precision_score(holdout_dataset.target, y_proba))\n",
    "    precision_recall_per_week.append([precision_score(holdout_dataset.target, y_pred), recall_score(holdout_dataset.target, y_pred)])\n",
    "    \n",
    "    if INTERACTIVE_MODE:\n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 6))\n",
    "        fig.suptitle(f'week_nr {week_nr} \\n Re-run this cell for the next week', fontsize=16)\n",
    "        ax2.set_title('Precision - recall curve')\n",
    "        training_data.target.value_counts().plot(kind='bar', title='Training data labels', ax=ax1)\n",
    "        ax1.grid(axis='y')\n",
    "        PrecisionRecallDisplay.from_predictions(holdout_dataset.target, y_proba, ax=ax2);\n",
    "        week_nr += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d1adf23-d29b-41b7-9042-04ca60119c42",
   "metadata": {
    "id": "8c7158f5-04f7-412a-a924-e38658a351bf"
   },
   "source": [
    "#### Now let's look at a summary of the active learning experiment. Did our model improve?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41de626a-e3ea-45ad-a322-1ff22b3b3ebe",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 924
    },
    "id": "38c7aae0-81a0-4586-bf3d-d889514a8137",
    "outputId": "7133b8fe-e2b9-4129-814a-bcb1a1ad7b25"
   },
   "outputs": [],
   "source": [
    "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(18, 14))\n",
    "fig.suptitle('Active learning summary', fontsize=16)\n",
    "plt.setp([ax1, ax2, ax3], xlabel='AL iteration')\n",
    "\n",
    "# Samples per iteration\n",
    "ax1.plot(range(1, len(labels_per_week) + 1), labels_per_week); ax1.grid(axis='y'); ax1.legend(['Number legitimate', 'Number fraudulent']); ax1.set_title('Training samples per iteration');\n",
    "ax2.plot(range(1, len(ap_per_week) + 1), ap_per_week); ax2.grid(axis='y'); ax2.set_title('Average Precision per iteration');\n",
    "ax3.plot(range(1, len(precision_recall_per_week) + 1), precision_recall_per_week); ax3.grid(axis='y'); ax3.legend(['Precision', 'Recall']); ax3.set_title('Precision and recall per iteration');\n",
    "PrecisionRecallDisplay.from_predictions(holdout_dataset.target, y_proba, ax=ax4); ax4.set_title('Final precision / recall curve');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3814c55a-eaea-4c92-92c6-86eab7e7ee86",
   "metadata": {
    "id": "60952aca-fd1f-41bf-b7b9-629d138ff458",
    "tags": []
   },
   "source": [
    "### Which of the sampling strategies worked best overall?\n",
    "### How do different classifiers perform before and after active learning?\n",
    "### How might we further improve the model?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TMA",
   "language": "python",
   "name": "tma"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
